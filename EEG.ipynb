{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "radDZj9Kw9BO",
        "outputId": "53056b24-635e-4c1c-a221-1c92ce81a9af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyedflib==0.1.30\n",
            "  Downloading pyEDFlib-0.1.30.tar.gz (1.7 MB)\n",
            "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "     ------------------------ --------------- 1.0/1.7 MB 41.9 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.7/1.7 MB 4.6 MB/s  0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Getting requirements to build wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [168 lines of output]\n",
            "      Compiling pyedflib\\_extensions\\_pyedflib.pyx because it changed.\n",
            "      [1/1] Cythonizing pyedflib\\_extensions\\_pyedflib.pyx\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "      \n",
            "      #from c_edf cimport *\n",
            "      import locale\n",
            "      import os\n",
            "      import warnings\n",
            "      cimport c_edf\n",
            "              ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:25:8: 'c_edf.pxd' not found\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "          needed according the montage and filter settings, then display the data.\n",
            "      \n",
            "          \"\"\"\n",
            "      \n",
            "      \n",
            "          cdef c_edf.edf_hdr_struct hdr\n",
            "               ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:137:9: 'edf_hdr_struct' is not a type identifier\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "      \n",
            "      cpdef int set_technician(int handle, char *technician):\n",
            "          return c_edf.edf_set_technician(handle, technician)\n",
            "      \n",
            "      cdef class EdfAnnotation:\n",
            "          cdef c_edf.edf_annotation_struct annotation\n",
            "               ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:457:9: 'edf_annotation_struct' is not a type identifier\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "              self.file_name = file_name\n",
            "      \n",
            "              return self.check_open_ok(result)\n",
            "      \n",
            "          def read_annotation(self):\n",
            "              cdef c_edf.edf_annotation_struct annot\n",
            "                   ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:212:13: 'edf_annotation_struct' is not a type identifier\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "                  return output_buf.value\n",
            "              else:\n",
            "                  output_buf_size = needed\n",
            "      \n",
            "      def lib_version():\n",
            "          return c_edf.edflib_version()\n",
            "                      ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:118:16: cimported module has no attribute 'edflib_version'\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "                      raise e\n",
            "      \n",
            "      \n",
            "          def __dealloc__(self):\n",
            "              if self.hdr.handle >= 0:\n",
            "                  c_edf.edfclose_file(self.hdr.handle)\n",
            "                       ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:171:17: cimported module has no attribute 'edfclose_file'\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "          def open(self, file_name, annotations_mode=EDFLIB_READ_ALL_ANNOTATIONS, check_file_size=EDFLIB_CHECK_FILE_SIZE):\n",
            "              \"\"\"\n",
            "              open(file_name, annotations_mode, check_file_size)\n",
            "              \"\"\"\n",
            "              file_name_str = file_name.encode('utf8','strict')\n",
            "              result = c_edf.edfopen_file_readonly(file_name_str, &self.hdr, annotations_mode, check_file_size)\n",
            "                            ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:205:22: cimported module has no attribute 'edfopen_file_readonly'\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "          def open(self, file_name, annotations_mode=EDFLIB_READ_ALL_ANNOTATIONS, check_file_size=EDFLIB_CHECK_FILE_SIZE):\n",
            "              \"\"\"\n",
            "              open(file_name, annotations_mode, check_file_size)\n",
            "              \"\"\"\n",
            "              file_name_str = file_name.encode('utf8','strict')\n",
            "              result = c_edf.edfopen_file_readonly(file_name_str, &self.hdr, annotations_mode, check_file_size)\n",
            "                            ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:205:22: Compiler crash in AnalyseExpressionsTransform\n",
            "      \n",
            "      ModuleNode.body = StatListNode(_pyedflib.pyx:6:0)\n",
            "      StatListNode.stats[20] = StatListNode(_pyedflib.pyx:120:0)\n",
            "      StatListNode.stats[0] = CClassDefNode(_pyedflib.pyx:120:0,\n",
            "          as_name = 'CyEdfReader',\n",
            "          class_name = 'CyEdfReader',\n",
            "          doc = '\\n    This provides a simple interface to read EDF, EDF+, and probably is ok with\\n    BDF and BDF+ files\\n    Note that edflib.c is encapsulated so there is no direct access to the file\\n    from here unless I add a raw interface or something\\n\\n    EDF/BDF+ files are arranged into N signals sampled at rate Fs. The data is actually stored in chunks called    \"datarecords\" which have a file specific size.\\n\\n    A typical way to use this to read an EEG file would be to choose a certain\\n    number of seconds per page to display. Then figureout how many data records\\n    that is. Then read in that many data records at a time. Transform the data as\\n    needed according the montage and filter settings, then display the data.\\n\\n    ',\n",
            "          module_name = '',\n",
            "          punycode_class_name = 'CyEdfReader',\n",
            "          visibility = 'private')\n",
            "      CClassDefNode.body = StatListNode(_pyedflib.pyx:121:4)\n",
            "      StatListNode.stats[6] = DefNode(_pyedflib.pyx:200:4,\n",
            "          doc = '\\n        open(file_name, annotations_mode, check_file_size)\\n        ',\n",
            "          is_cyfunction = True,\n",
            "          modifiers = [...]/0,\n",
            "          name = 'open',\n",
            "          np_args_idx = [...]/0,\n",
            "          num_required_args = 2,\n",
            "          outer_attrs = [...]/2,\n",
            "          py_wrapper_required = True,\n",
            "          reqd_kw_flags_cname = '0',\n",
            "          used = True)\n",
            "      File 'ExprNodes.py', line 6078, in infer_type: SimpleCallNode(_pyedflib.pyx:205:44,\n",
            "          result_is_used = True,\n",
            "          use_managed_ref = True)\n",
            "      File 'ExprNodes.py', line 7806, in infer_type: AttributeNode(_pyedflib.pyx:205:22,\n",
            "          attribute = 'edfopen_file_readonly',\n",
            "          is_attribute = 1,\n",
            "          needs_none_check = True,\n",
            "          result_is_used = True,\n",
            "          use_managed_ref = True)\n",
            "      \n",
            "      Compiler crash traceback from this point on:\n",
            "        File \"C:\\Users\\arshv\\AppData\\Local\\Temp\\pip-build-env-nscypmsu\\overlay\\Lib\\site-packages\\Cython\\Compiler\\ExprNodes.py\", line 7806, in infer_type\n",
            "          if node.entry.type and node.entry.type.is_cfunction:\n",
            "             ^^^^^^^^^^^^^^^\n",
            "      AttributeError: 'NoneType' object has no attribute 'type'\n",
            "      Traceback (most recent call last):\n",
            "        File \u001b[35m\"C:\\ASK_Main\\ASK_College_Tpoly\\DHS_AC_MASTERS\\DHS\\Code\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "          \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
            "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\ASK_Main\\ASK_College_Tpoly\\DHS_AC_MASTERS\\DHS\\Code\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
            "          json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
            "                                   \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\ASK_Main\\ASK_College_Tpoly\\DHS_AC_MASTERS\\DHS\\Code\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
            "          return hook(config_settings)\n",
            "        File \u001b[35m\"C:\\Users\\arshv\\AppData\\Local\\Temp\\pip-build-env-nscypmsu\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m333\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
            "          return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
            "                 \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\arshv\\AppData\\Local\\Temp\\pip-build-env-nscypmsu\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
            "          \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
            "          \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\arshv\\AppData\\Local\\Temp\\pip-build-env-nscypmsu\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
            "          \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
            "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m266\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\arshv\\AppData\\Local\\Temp\\pip-build-env-nscypmsu\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\"\u001b[0m, line \u001b[35m1153\u001b[0m, in \u001b[35mcythonize\u001b[0m\n",
            "          \u001b[31mcythonize_one\u001b[0m\u001b[1;31m(*args)\u001b[0m\n",
            "          \u001b[31m~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\arshv\\AppData\\Local\\Temp\\pip-build-env-nscypmsu\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\"\u001b[0m, line \u001b[35m1297\u001b[0m, in \u001b[35mcythonize_one\u001b[0m\n",
            "          raise CompileError(None, pyx_file)\n",
            "      \u001b[1;35mCython.Compiler.Errors.CompileError\u001b[0m: \u001b[35mpyedflib\\_extensions\\_pyedflib.pyx\u001b[0m\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× Getting requirements to build wheel did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl.metadata (4.6 kB)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow)\n",
            "  Downloading absl_py-2.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
            "  Downloading gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
            "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (26.0)\n",
            "Collecting protobuf>=5.28.0 (from tensorflow)\n",
            "  Downloading protobuf-6.33.5-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
            "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting setuptools (from tensorflow)\n",
            "  Using cached setuptools-80.10.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow)\n",
            "  Downloading termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting typing_extensions>=3.6.6 (from tensorflow)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting wrapt>=1.11.0 (from tensorflow)\n",
            "  Using cached wrapt-2.0.1-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
            "  Using cached grpcio-1.76.0-cp313-cp313-win_amd64.whl.metadata (3.8 kB)\n",
            "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting keras>=3.10.0 (from tensorflow)\n",
            "  Downloading keras-3.13.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting numpy>=1.26.0 (from tensorflow)\n",
            "  Using cached numpy-2.4.1-cp313-cp313-win_amd64.whl.metadata (6.6 kB)\n",
            "Collecting h5py>=3.11.0 (from tensorflow)\n",
            "  Downloading h5py-3.15.1-cp313-cp313-win_amd64.whl.metadata (3.1 kB)\n",
            "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.5.4-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
            "  Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
            "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
            "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
            "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading markdown-3.10.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pillow (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading pillow-12.1.0-cp313-cp313-win_amd64.whl.metadata (9.0 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.5-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Using cached wheel-0.46.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting rich (from keras>=3.10.0->tensorflow)\n",
            "  Downloading rich-14.3.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting namex (from keras>=3.10.0->tensorflow)\n",
            "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
            "Collecting optree (from keras>=3.10.0->tensorflow)\n",
            "  Downloading optree-0.18.0-cp313-cp313-win_amd64.whl.metadata (35 kB)\n",
            "Collecting markupsafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow)\n",
            "  Using cached markupsafe-3.0.3-cp313-cp313-win_amd64.whl.metadata (2.8 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
            "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl (332.0 MB)\n",
            "   ---------------------------------------- 0.0/332.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 3.9/332.0 MB 19.6 MB/s eta 0:00:17\n",
            "    --------------------------------------- 6.6/332.0 MB 16.1 MB/s eta 0:00:21\n",
            "   - -------------------------------------- 9.4/332.0 MB 15.0 MB/s eta 0:00:22\n",
            "   - -------------------------------------- 12.3/332.0 MB 14.5 MB/s eta 0:00:23\n",
            "   - -------------------------------------- 14.9/332.0 MB 14.1 MB/s eta 0:00:23\n",
            "   -- ------------------------------------- 17.3/332.0 MB 14.0 MB/s eta 0:00:23\n",
            "   -- ------------------------------------- 20.2/332.0 MB 13.8 MB/s eta 0:00:23\n",
            "   -- ------------------------------------- 22.8/332.0 MB 13.7 MB/s eta 0:00:23\n",
            "   --- ------------------------------------ 25.4/332.0 MB 13.6 MB/s eta 0:00:23\n",
            "   --- ------------------------------------ 28.3/332.0 MB 13.5 MB/s eta 0:00:23\n",
            "   --- ------------------------------------ 30.9/332.0 MB 13.5 MB/s eta 0:00:23\n",
            "   ---- ----------------------------------- 33.6/332.0 MB 13.4 MB/s eta 0:00:23\n",
            "   ---- ----------------------------------- 35.9/332.0 MB 13.3 MB/s eta 0:00:23\n",
            "   ---- ----------------------------------- 38.5/332.0 MB 13.3 MB/s eta 0:00:23\n",
            "   ---- ----------------------------------- 41.2/332.0 MB 13.2 MB/s eta 0:00:22\n",
            "   ----- ---------------------------------- 43.5/332.0 MB 13.1 MB/s eta 0:00:22\n",
            "   ----- ---------------------------------- 45.9/332.0 MB 12.9 MB/s eta 0:00:23\n",
            "   ----- ---------------------------------- 48.2/332.0 MB 12.9 MB/s eta 0:00:23\n",
            "   ------ --------------------------------- 50.9/332.0 MB 12.9 MB/s eta 0:00:22\n",
            "   ------ --------------------------------- 53.5/332.0 MB 12.9 MB/s eta 0:00:22\n",
            "   ------ --------------------------------- 56.4/332.0 MB 12.9 MB/s eta 0:00:22\n",
            "   ------- -------------------------------- 59.2/332.0 MB 12.9 MB/s eta 0:00:22\n",
            "   ------- -------------------------------- 61.9/332.0 MB 12.9 MB/s eta 0:00:21\n",
            "   ------- -------------------------------- 64.5/332.0 MB 12.9 MB/s eta 0:00:21\n",
            "   -------- ------------------------------- 67.4/332.0 MB 12.9 MB/s eta 0:00:21\n",
            "   -------- ------------------------------- 70.0/332.0 MB 12.9 MB/s eta 0:00:21\n",
            "   -------- ------------------------------- 72.6/332.0 MB 12.9 MB/s eta 0:00:21\n",
            "   --------- ------------------------------ 75.5/332.0 MB 12.9 MB/s eta 0:00:20\n",
            "   --------- ------------------------------ 78.1/332.0 MB 12.9 MB/s eta 0:00:20\n",
            "   --------- ------------------------------ 80.7/332.0 MB 12.9 MB/s eta 0:00:20\n",
            "   ---------- ----------------------------- 83.4/332.0 MB 12.9 MB/s eta 0:00:20\n",
            "   ---------- ----------------------------- 85.2/332.0 MB 12.9 MB/s eta 0:00:20\n",
            "   ---------- ----------------------------- 88.6/332.0 MB 12.9 MB/s eta 0:00:19\n",
            "   ---------- ----------------------------- 90.7/332.0 MB 12.8 MB/s eta 0:00:19\n",
            "   ----------- ---------------------------- 92.8/332.0 MB 12.7 MB/s eta 0:00:19\n",
            "   ----------- ---------------------------- 95.7/332.0 MB 12.7 MB/s eta 0:00:19\n",
            "   ----------- ---------------------------- 98.3/332.0 MB 12.7 MB/s eta 0:00:19\n",
            "   ----------- --------------------------- 100.9/332.0 MB 12.7 MB/s eta 0:00:19\n",
            "   ------------ -------------------------- 103.5/332.0 MB 12.8 MB/s eta 0:00:18\n",
            "   ------------ -------------------------- 106.2/332.0 MB 12.8 MB/s eta 0:00:18\n",
            "   ------------ -------------------------- 108.8/332.0 MB 12.8 MB/s eta 0:00:18\n",
            "   ------------- ------------------------- 111.4/332.0 MB 12.8 MB/s eta 0:00:18\n",
            "   ------------- ------------------------- 114.3/332.0 MB 12.8 MB/s eta 0:00:18\n",
            "   ------------- ------------------------- 116.9/332.0 MB 12.8 MB/s eta 0:00:17\n",
            "   -------------- ------------------------ 119.5/332.0 MB 12.8 MB/s eta 0:00:17\n",
            "   -------------- ------------------------ 122.2/332.0 MB 12.8 MB/s eta 0:00:17\n",
            "   -------------- ------------------------ 125.0/332.0 MB 12.8 MB/s eta 0:00:17\n",
            "   -------------- ------------------------ 127.7/332.0 MB 12.8 MB/s eta 0:00:16\n",
            "   --------------- ----------------------- 130.3/332.0 MB 12.8 MB/s eta 0:00:16\n",
            "   --------------- ----------------------- 132.9/332.0 MB 12.8 MB/s eta 0:00:16\n",
            "   --------------- ----------------------- 135.3/332.0 MB 12.8 MB/s eta 0:00:16\n",
            "   ---------------- ---------------------- 137.9/332.0 MB 12.8 MB/s eta 0:00:16\n",
            "   ---------------- ---------------------- 140.2/332.0 MB 12.8 MB/s eta 0:00:16\n",
            "   ---------------- ---------------------- 142.9/332.0 MB 12.7 MB/s eta 0:00:15\n",
            "   ----------------- --------------------- 145.2/332.0 MB 12.7 MB/s eta 0:00:15\n",
            "   ----------------- --------------------- 147.8/332.0 MB 12.7 MB/s eta 0:00:15\n",
            "   ----------------- --------------------- 150.5/332.0 MB 12.7 MB/s eta 0:00:15\n",
            "   ------------------ -------------------- 153.4/332.0 MB 12.7 MB/s eta 0:00:15\n",
            "   ------------------ -------------------- 156.0/332.0 MB 12.7 MB/s eta 0:00:14\n",
            "   ------------------ -------------------- 158.9/332.0 MB 12.7 MB/s eta 0:00:14\n",
            "   ------------------ -------------------- 161.5/332.0 MB 12.7 MB/s eta 0:00:14\n",
            "   ------------------- ------------------- 164.4/332.0 MB 12.7 MB/s eta 0:00:14\n",
            "   ------------------- ------------------- 167.0/332.0 MB 12.7 MB/s eta 0:00:13\n",
            "   ------------------- ------------------- 169.6/332.0 MB 12.8 MB/s eta 0:00:13\n",
            "   -------------------- ------------------ 172.5/332.0 MB 12.8 MB/s eta 0:00:13\n",
            "   -------------------- ------------------ 175.1/332.0 MB 12.8 MB/s eta 0:00:13\n",
            "   -------------------- ------------------ 177.7/332.0 MB 12.8 MB/s eta 0:00:13\n",
            "   --------------------- ----------------- 180.4/332.0 MB 12.8 MB/s eta 0:00:12\n",
            "   --------------------- ----------------- 183.0/332.0 MB 12.8 MB/s eta 0:00:12\n",
            "   --------------------- ----------------- 185.6/332.0 MB 12.8 MB/s eta 0:00:12\n",
            "   ---------------------- ---------------- 188.2/332.0 MB 12.7 MB/s eta 0:00:12\n",
            "   ---------------------- ---------------- 190.6/332.0 MB 12.7 MB/s eta 0:00:12\n",
            "   ---------------------- ---------------- 193.2/332.0 MB 12.7 MB/s eta 0:00:11\n",
            "   ----------------------- --------------- 195.8/332.0 MB 12.7 MB/s eta 0:00:11\n",
            "   ----------------------- --------------- 198.4/332.0 MB 12.7 MB/s eta 0:00:11\n",
            "   ----------------------- --------------- 200.8/332.0 MB 12.7 MB/s eta 0:00:11\n",
            "   ----------------------- --------------- 203.4/332.0 MB 12.7 MB/s eta 0:00:11\n",
            "   ------------------------ -------------- 206.0/332.0 MB 12.7 MB/s eta 0:00:10\n",
            "   ------------------------ -------------- 208.7/332.0 MB 12.7 MB/s eta 0:00:10\n",
            "   ------------------------ -------------- 211.3/332.0 MB 12.7 MB/s eta 0:00:10\n",
            "   ------------------------- ------------- 214.2/332.0 MB 12.7 MB/s eta 0:00:10\n",
            "   ------------------------- ------------- 216.8/332.0 MB 12.7 MB/s eta 0:00:10\n",
            "   ------------------------- ------------- 219.4/332.0 MB 12.7 MB/s eta 0:00:09\n",
            "   -------------------------- ------------ 221.8/332.0 MB 12.7 MB/s eta 0:00:09\n",
            "   -------------------------- ------------ 224.4/332.0 MB 12.7 MB/s eta 0:00:09\n",
            "   -------------------------- ------------ 227.0/332.0 MB 12.7 MB/s eta 0:00:09\n",
            "   -------------------------- ------------ 229.6/332.0 MB 12.7 MB/s eta 0:00:09\n",
            "   --------------------------- ----------- 232.3/332.0 MB 12.7 MB/s eta 0:00:08\n",
            "   --------------------------- ----------- 234.9/332.0 MB 12.7 MB/s eta 0:00:08\n",
            "   --------------------------- ----------- 237.2/332.0 MB 12.7 MB/s eta 0:00:08\n",
            "   ---------------------------- ---------- 239.9/332.0 MB 12.7 MB/s eta 0:00:08\n",
            "   ---------------------------- ---------- 242.5/332.0 MB 12.7 MB/s eta 0:00:08\n",
            "   ---------------------------- ---------- 245.1/332.0 MB 12.7 MB/s eta 0:00:07\n",
            "   ----------------------------- --------- 247.5/332.0 MB 12.7 MB/s eta 0:00:07\n",
            "   ----------------------------- --------- 250.3/332.0 MB 12.7 MB/s eta 0:00:07\n",
            "   ----------------------------- --------- 252.7/332.0 MB 12.7 MB/s eta 0:00:07\n",
            "   ------------------------------ -------- 255.6/332.0 MB 12.7 MB/s eta 0:00:07\n",
            "   ------------------------------ -------- 258.2/332.0 MB 12.7 MB/s eta 0:00:06\n",
            "   ------------------------------ -------- 261.1/332.0 MB 12.7 MB/s eta 0:00:06\n",
            "   ------------------------------ -------- 263.7/332.0 MB 12.6 MB/s eta 0:00:06\n",
            "   ------------------------------- ------- 266.3/332.0 MB 12.6 MB/s eta 0:00:06\n",
            "   ------------------------------- ------- 269.0/332.0 MB 12.6 MB/s eta 0:00:05\n",
            "   ------------------------------- ------- 271.6/332.0 MB 12.6 MB/s eta 0:00:05\n",
            "   -------------------------------- ------ 274.2/332.0 MB 12.6 MB/s eta 0:00:05\n",
            "   -------------------------------- ------ 276.8/332.0 MB 12.6 MB/s eta 0:00:05\n",
            "   -------------------------------- ------ 279.7/332.0 MB 12.6 MB/s eta 0:00:05\n",
            "   --------------------------------- ----- 282.3/332.0 MB 12.6 MB/s eta 0:00:04\n",
            "   --------------------------------- ----- 284.7/332.0 MB 12.6 MB/s eta 0:00:04\n",
            "   --------------------------------- ----- 287.3/332.0 MB 12.6 MB/s eta 0:00:04\n",
            "   ---------------------------------- ---- 289.9/332.0 MB 12.6 MB/s eta 0:00:04\n",
            "   ---------------------------------- ---- 292.6/332.0 MB 12.6 MB/s eta 0:00:04\n",
            "   ---------------------------------- ---- 295.2/332.0 MB 12.6 MB/s eta 0:00:03\n",
            "   ---------------------------------- ---- 297.8/332.0 MB 12.6 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 300.7/332.0 MB 12.6 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 303.0/332.0 MB 12.6 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 305.7/332.0 MB 12.7 MB/s eta 0:00:03\n",
            "   ------------------------------------ -- 308.3/332.0 MB 12.7 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 311.2/332.0 MB 12.7 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 313.8/332.0 MB 12.7 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 316.4/332.0 MB 12.7 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 319.3/332.0 MB 12.7 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 321.9/332.0 MB 12.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  324.8/332.0 MB 12.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  327.4/332.0 MB 12.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  330.0/332.0 MB 12.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  331.9/332.0 MB 12.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  331.9/332.0 MB 12.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 332.0/332.0 MB 12.4 MB/s  0:00:26\n",
            "Using cached grpcio-1.76.0-cp313-cp313-win_amd64.whl (4.7 MB)\n",
            "Downloading ml_dtypes-0.5.4-cp313-cp313-win_amd64.whl (212 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
            "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
            "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
            "   ---------------------------- ----------- 3.9/5.5 MB 18.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 5.5/5.5 MB 15.9 MB/s  0:00:00\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
            "Downloading absl_py-2.4.0-py3-none-any.whl (135 kB)\n",
            "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Using cached wheel-0.46.3-py3-none-any.whl (30 kB)\n",
            "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
            "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
            "Downloading gast-0.7.0-py3-none-any.whl (22 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Downloading h5py-3.15.1-cp313-cp313-win_amd64.whl (2.9 MB)\n",
            "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.9/2.9 MB 20.6 MB/s  0:00:00\n",
            "Downloading keras-3.13.2-py3-none-any.whl (1.5 MB)\n",
            "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.5/1.5 MB 13.0 MB/s  0:00:00\n",
            "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
            "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
            "   --- ------------------------------------ 2.1/26.4 MB 13.3 MB/s eta 0:00:02\n",
            "   ------- -------------------------------- 5.2/26.4 MB 13.0 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 7.9/26.4 MB 12.9 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 10.5/26.4 MB 12.8 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 13.1/26.4 MB 12.8 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 15.7/26.4 MB 12.8 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 18.4/26.4 MB 12.7 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 20.7/26.4 MB 12.7 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 23.3/26.4 MB 12.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  26.0/26.4 MB 12.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 26.4/26.4 MB 12.5 MB/s  0:00:02\n",
            "Downloading markdown-3.10.1-py3-none-any.whl (107 kB)\n",
            "Using cached numpy-2.4.1-cp313-cp313-win_amd64.whl (12.3 MB)\n",
            "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Downloading protobuf-6.33.5-cp310-abi3-win_amd64.whl (437 kB)\n",
            "Using cached setuptools-80.10.2-py3-none-any.whl (1.1 MB)\n",
            "Downloading termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading werkzeug-3.1.5-py3-none-any.whl (225 kB)\n",
            "Using cached markupsafe-3.0.3-cp313-cp313-win_amd64.whl (15 kB)\n",
            "Using cached wrapt-2.0.1-cp313-cp313-win_amd64.whl (60 kB)\n",
            "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
            "Downloading optree-0.18.0-cp313-cp313-win_amd64.whl (314 kB)\n",
            "Downloading pillow-12.1.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
            "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
            "   -------------------- ------------------- 3.7/7.0 MB 17.6 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 6.0/7.0 MB 15.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 7.0/7.0 MB 14.2 MB/s  0:00:00\n",
            "Downloading rich-14.3.1-py3-none-any.whl (309 kB)\n",
            "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, typing_extensions, termcolor, tensorboard-data-server, setuptools, protobuf, pillow, opt_einsum, numpy, mdurl, markupsafe, markdown, idna, google_pasta, gast, charset_normalizer, certifi, absl-py, werkzeug, requests, optree, ml_dtypes, markdown-it-py, h5py, grpcio, astunparse, tensorboard, rich, keras, tensorflow\n",
            "\n",
            "   - --------------------------------------  1/35 [libclang]\n",
            "   - --------------------------------------  1/35 [libclang]\n",
            "   - --------------------------------------  1/35 [libclang]\n",
            "   -- -------------------------------------  2/35 [flatbuffers]\n",
            "   --- ------------------------------------  3/35 [wrapt]\n",
            "   ---- -----------------------------------  4/35 [wheel]\n",
            "   ---- -----------------------------------  4/35 [wheel]\n",
            "   ----- ----------------------------------  5/35 [urllib3]\n",
            "   ----- ----------------------------------  5/35 [urllib3]\n",
            "   ----- ----------------------------------  5/35 [urllib3]\n",
            "   ----- ----------------------------------  5/35 [urllib3]\n",
            "   ----- ----------------------------------  5/35 [urllib3]\n",
            "   -------- -------------------------------  7/35 [termcolor]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ---------- -----------------------------  9/35 [setuptools]\n",
            "   ----------- ---------------------------- 10/35 [protobuf]\n",
            "   ----------- ---------------------------- 10/35 [protobuf]\n",
            "   ----------- ---------------------------- 10/35 [protobuf]\n",
            "   ----------- ---------------------------- 10/35 [protobuf]\n",
            "   ----------- ---------------------------- 10/35 [protobuf]\n",
            "   ----------- ---------------------------- 10/35 [protobuf]\n",
            "   ----------- ---------------------------- 10/35 [protobuf]\n",
            "   ------------ --------------------------- 11/35 [pillow]\n",
            "   ------------ --------------------------- 11/35 [pillow]\n",
            "   ------------ --------------------------- 11/35 [pillow]\n",
            "   ------------ --------------------------- 11/35 [pillow]\n",
            "   ------------ --------------------------- 11/35 [pillow]\n",
            "   ------------ --------------------------- 11/35 [pillow]\n",
            "   ------------ --------------------------- 11/35 [pillow]\n",
            "   ------------ --------------------------- 11/35 [pillow]\n",
            "   ------------ --------------------------- 11/35 [pillow]\n",
            "   ------------ --------------------------- 11/35 [pillow]\n",
            "   ------------ --------------------------- 11/35 [pillow]\n",
            "   ------------ --------------------------- 11/35 [pillow]\n",
            "   ------------ --------------------------- 11/35 [pillow]\n",
            "   ------------- -------------------------- 12/35 [opt_einsum]\n",
            "   ------------- -------------------------- 12/35 [opt_einsum]\n",
            "   ------------- -------------------------- 12/35 [opt_einsum]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   -------------- ------------------------- 13/35 [numpy]\n",
            "   ----------------- ---------------------- 15/35 [markupsafe]\n",
            "   ------------------ --------------------- 16/35 [markdown]\n",
            "   ------------------ --------------------- 16/35 [markdown]\n",
            "   ------------------ --------------------- 16/35 [markdown]\n",
            "   ------------------ --------------------- 16/35 [markdown]\n",
            "   ------------------ --------------------- 16/35 [markdown]\n",
            "   ------------------- -------------------- 17/35 [idna]\n",
            "   -------------------- ------------------- 18/35 [google_pasta]\n",
            "   -------------------- ------------------- 18/35 [google_pasta]\n",
            "   -------------------- ------------------- 18/35 [google_pasta]\n",
            "   -------------------- ------------------- 18/35 [google_pasta]\n",
            "   --------------------- ------------------ 19/35 [gast]\n",
            "   ---------------------- ----------------- 20/35 [charset_normalizer]\n",
            "   ---------------------- ----------------- 20/35 [charset_normalizer]\n",
            "   ------------------------ --------------- 21/35 [certifi]\n",
            "   ------------------------- -------------- 22/35 [absl-py]\n",
            "   ------------------------- -------------- 22/35 [absl-py]\n",
            "   ------------------------- -------------- 22/35 [absl-py]\n",
            "   -------------------------- ------------- 23/35 [werkzeug]\n",
            "   -------------------------- ------------- 23/35 [werkzeug]\n",
            "   -------------------------- ------------- 23/35 [werkzeug]\n",
            "   -------------------------- ------------- 23/35 [werkzeug]\n",
            "   -------------------------- ------------- 23/35 [werkzeug]\n",
            "   -------------------------- ------------- 23/35 [werkzeug]\n",
            "   --------------------------- ------------ 24/35 [requests]\n",
            "   --------------------------- ------------ 24/35 [requests]\n",
            "   ---------------------------- ----------- 25/35 [optree]\n",
            "   ---------------------------- ----------- 25/35 [optree]\n",
            "   ------------------------------ --------- 27/35 [markdown-it-py]\n",
            "   ------------------------------ --------- 27/35 [markdown-it-py]\n",
            "   ------------------------------ --------- 27/35 [markdown-it-py]\n",
            "   ------------------------------ --------- 27/35 [markdown-it-py]\n",
            "   ------------------------------ --------- 27/35 [markdown-it-py]\n",
            "   ------------------------------ --------- 27/35 [markdown-it-py]\n",
            "   ------------------------------ --------- 27/35 [markdown-it-py]\n",
            "   -------------------------------- ------- 28/35 [h5py]\n",
            "   -------------------------------- ------- 28/35 [h5py]\n",
            "   -------------------------------- ------- 28/35 [h5py]\n",
            "   -------------------------------- ------- 28/35 [h5py]\n",
            "   -------------------------------- ------- 28/35 [h5py]\n",
            "   -------------------------------- ------- 28/35 [h5py]\n",
            "   -------------------------------- ------- 28/35 [h5py]\n",
            "   -------------------------------- ------- 28/35 [h5py]\n",
            "   --------------------------------- ------ 29/35 [grpcio]\n",
            "   --------------------------------- ------ 29/35 [grpcio]\n",
            "   --------------------------------- ------ 29/35 [grpcio]\n",
            "   --------------------------------- ------ 29/35 [grpcio]\n",
            "   --------------------------------- ------ 29/35 [grpcio]\n",
            "   --------------------------------- ------ 29/35 [grpcio]\n",
            "   ---------------------------------- ----- 30/35 [astunparse]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ----------------------------------- ---- 31/35 [tensorboard]\n",
            "   ------------------------------------ --- 32/35 [rich]\n",
            "   ------------------------------------ --- 32/35 [rich]\n",
            "   ------------------------------------ --- 32/35 [rich]\n",
            "   ------------------------------------ --- 32/35 [rich]\n",
            "   ------------------------------------ --- 32/35 [rich]\n",
            "   ------------------------------------ --- 32/35 [rich]\n",
            "   ------------------------------------ --- 32/35 [rich]\n",
            "   ------------------------------------ --- 32/35 [rich]\n",
            "   ------------------------------------ --- 32/35 [rich]\n",
            "   ------------------------------------ --- 32/35 [rich]\n",
            "   ------------------------------------ --- 32/35 [rich]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   ------------------------------------- -- 33/35 [keras]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   -------------------------------------- - 34/35 [tensorflow]\n",
            "   ---------------------------------------- 35/35 [tensorflow]\n",
            "\n",
            "Successfully installed absl-py-2.4.0 astunparse-1.6.3 certifi-2026.1.4 charset_normalizer-3.4.4 flatbuffers-25.12.19 gast-0.7.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 idna-3.11 keras-3.13.2 libclang-18.1.1 markdown-3.10.1 markdown-it-py-4.0.0 markupsafe-3.0.3 mdurl-0.1.2 ml_dtypes-0.5.4 namex-0.1.0 numpy-2.4.1 opt_einsum-3.4.0 optree-0.18.0 pillow-12.1.0 protobuf-6.33.5 requests-2.32.5 rich-14.3.1 setuptools-80.10.2 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.3.0 typing_extensions-4.15.0 urllib3-2.6.3 werkzeug-3.1.5 wheel-0.46.3 wrapt-2.0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.8.0-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.24.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from scikit-learn) (2.4.1)\n",
            "Collecting scipy>=1.10.0 (from scikit-learn)\n",
            "  Downloading scipy-1.17.0-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
            "Collecting joblib>=1.3.0 (from scikit-learn)\n",
            "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.8.0-cp313-cp313-win_amd64.whl (8.0 MB)\n",
            "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
            "   --------------- ------------------------ 3.1/8.0 MB 22.2 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 6.3/8.0 MB 14.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.0/8.0 MB 14.0 MB/s  0:00:00\n",
            "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
            "Downloading scipy-1.17.0-cp313-cp313-win_amd64.whl (36.3 MB)\n",
            "   ---------------------------------------- 0.0/36.3 MB ? eta -:--:--\n",
            "   --- ------------------------------------ 2.9/36.3 MB 13.2 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 5.5/36.3 MB 13.1 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 7.9/36.3 MB 13.0 MB/s eta 0:00:03\n",
            "   ----------- ---------------------------- 10.7/36.3 MB 13.0 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 13.4/36.3 MB 13.0 MB/s eta 0:00:02\n",
            "   ----------------- ---------------------- 16.0/36.3 MB 13.0 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 17.6/36.3 MB 12.8 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 20.2/36.3 MB 12.4 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 22.5/36.3 MB 12.3 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 25.2/36.3 MB 12.4 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 28.0/36.3 MB 12.4 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 30.7/36.3 MB 12.5 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 33.6/36.3 MB 12.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  36.2/36.3 MB 12.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 36.3/36.3 MB 12.1 MB/s  0:00:02\n",
            "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
            "\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ---------------------------------------- 4/4 [scikit-learn]\n",
            "\n",
            "Successfully installed joblib-1.5.3 scikit-learn-1.8.0 scipy-1.17.0 threadpoolctl-3.6.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.8-cp313-cp313-win_amd64.whl.metadata (52 kB)\n",
            "Collecting seaborn\n",
            "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Using cached contourpy-1.3.3-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.61.1-cp313-cp313-win_amd64.whl.metadata (116 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Using cached kiwisolver-1.4.9-cp313-cp313-win_amd64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (2.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (12.1.0)\n",
            "Collecting pyparsing>=3 (from matplotlib)\n",
            "  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Collecting pandas>=1.2 (from seaborn)\n",
            "  Downloading pandas-3.0.0-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
            "Collecting tzdata (from pandas>=1.2->seaborn)\n",
            "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading matplotlib-3.10.8-cp313-cp313-win_amd64.whl (8.1 MB)\n",
            "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
            "   ------------------ --------------------- 3.7/8.1 MB 19.2 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 6.6/8.1 MB 15.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.1/8.1 MB 14.3 MB/s  0:00:00\n",
            "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Using cached contourpy-1.3.3-cp313-cp313-win_amd64.whl (226 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.61.1-cp313-cp313-win_amd64.whl (2.3 MB)\n",
            "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.3/2.3 MB 22.4 MB/s  0:00:00\n",
            "Using cached kiwisolver-1.4.9-cp313-cp313-win_amd64.whl (73 kB)\n",
            "Downloading pandas-3.0.0-cp313-cp313-win_amd64.whl (9.7 MB)\n",
            "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
            "   ------------ --------------------------- 3.1/9.7 MB 14.5 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 5.8/9.7 MB 13.5 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 8.1/9.7 MB 13.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 9.7/9.7 MB 11.8 MB/s  0:00:00\n",
            "Downloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
            "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
            "Installing collected packages: tzdata, pyparsing, kiwisolver, fonttools, cycler, contourpy, pandas, matplotlib, seaborn\n",
            "\n",
            "   ---------------------------------------- 0/9 [tzdata]\n",
            "   ---------------------------------------- 0/9 [tzdata]\n",
            "   ---- ----------------------------------- 1/9 [pyparsing]\n",
            "   ---- ----------------------------------- 1/9 [pyparsing]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ------------- -------------------------- 3/9 [fonttools]\n",
            "   ----------------- ---------------------- 4/9 [cycler]\n",
            "   ---------------------- ----------------- 5/9 [contourpy]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   -------------------------- ------------- 6/9 [pandas]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ------------------------------- -------- 7/9 [matplotlib]\n",
            "   ----------------------------------- ---- 8/9 [seaborn]\n",
            "   ----------------------------------- ---- 8/9 [seaborn]\n",
            "   ----------------------------------- ---- 8/9 [seaborn]\n",
            "   ----------------------------------- ---- 8/9 [seaborn]\n",
            "   ----------------------------------- ---- 8/9 [seaborn]\n",
            "   ----------------------------------- ---- 8/9 [seaborn]\n",
            "   ----------------------------------- ---- 8/9 [seaborn]\n",
            "   ---------------------------------------- 9/9 [seaborn]\n",
            "\n",
            "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8 pandas-3.0.0 pyparsing-3.3.2 seaborn-0.13.2 tzdata-2025.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (1.17.0)\n",
            "Requirement already satisfied: numpy in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (2.4.1)\n",
            "Requirement already satisfied: pandas in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (3.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joblib in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (1.5.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install pyedflib==0.1.30\n",
        "!pip install tensorflow\n",
        "!pip install scikit-learn\n",
        "!pip install matplotlib seaborn\n",
        "!pip install scipy numpy pandas\n",
        "!pip install joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_MPiUY1w9yy",
        "outputId": "71ed6f61-8eda-44f4-a689-1461d790251a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mne==1.5.1\n",
            "  Downloading mne-1.5.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: numpy>=1.15.4 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from mne==1.5.1) (2.4.1)\n",
            "Requirement already satisfied: scipy>=1.6.3 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from mne==1.5.1) (1.17.0)\n",
            "Requirement already satisfied: matplotlib>=3.4.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from mne==1.5.1) (3.10.8)\n",
            "Collecting tqdm (from mne==1.5.1)\n",
            "  Downloading tqdm-4.67.2-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting pooch>=1.5 (from mne==1.5.1)\n",
            "  Downloading pooch-1.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: decorator in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from mne==1.5.1) (5.2.1)\n",
            "Requirement already satisfied: packaging in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from mne==1.5.1) (26.0)\n",
            "Collecting jinja2 (from mne==1.5.1)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib>=3.4.0->mne==1.5.1) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib>=3.4.0->mne==1.5.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib>=3.4.0->mne==1.5.1) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib>=3.4.0->mne==1.5.1) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib>=3.4.0->mne==1.5.1) (12.1.0)\n",
            "Requirement already satisfied: pyparsing>=3 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib>=3.4.0->mne==1.5.1) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib>=3.4.0->mne==1.5.1) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from pooch>=1.5->mne==1.5.1) (4.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from pooch>=1.5->mne==1.5.1) (2.32.5)\n",
            "Requirement already satisfied: six>=1.5 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->mne==1.5.1) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne==1.5.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne==1.5.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne==1.5.1) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne==1.5.1) (2026.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from jinja2->mne==1.5.1) (3.0.3)\n",
            "Requirement already satisfied: colorama in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tqdm->mne==1.5.1) (0.4.6)\n",
            "Downloading mne-1.5.1-py3-none-any.whl (7.7 MB)\n",
            "   ---------------------------------------- 0.0/7.7 MB ? eta -:--:--\n",
            "   ----- ---------------------------------- 1.0/7.7 MB 20.6 MB/s eta 0:00:01\n",
            "   ----- ---------------------------------- 1.0/7.7 MB 20.6 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 2.1/7.7 MB 4.1 MB/s eta 0:00:02\n",
            "   ---------- ----------------------------- 2.1/7.7 MB 4.1 MB/s eta 0:00:02\n",
            "   ---------- ----------------------------- 2.1/7.7 MB 4.1 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 3.1/7.7 MB 2.5 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 3.1/7.7 MB 2.5 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 3.1/7.7 MB 2.5 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 3.1/7.7 MB 2.5 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 4.2/7.7 MB 2.0 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 4.2/7.7 MB 2.0 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 5.2/7.7 MB 2.1 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 5.2/7.7 MB 2.1 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 5.2/7.7 MB 2.1 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 6.3/7.7 MB 2.0 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 6.3/7.7 MB 2.0 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 7.3/7.7 MB 2.1 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 7.3/7.7 MB 2.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 7.7/7.7 MB 2.0 MB/s  0:00:03\n",
            "Downloading pooch-1.9.0-py3-none-any.whl (67 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading tqdm-4.67.2-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm, jinja2, pooch, mne\n",
            "\n",
            "   ---------------------------------------- 0/4 [tqdm]\n",
            "   ---------------------------------------- 0/4 [tqdm]\n",
            "   ---------------------------------------- 0/4 [tqdm]\n",
            "   ---------- ----------------------------- 1/4 [jinja2]\n",
            "   ---------- ----------------------------- 1/4 [jinja2]\n",
            "   ---------- ----------------------------- 1/4 [jinja2]\n",
            "   ---------- ----------------------------- 1/4 [jinja2]\n",
            "   -------------------- ------------------- 2/4 [pooch]\n",
            "   -------------------- ------------------- 2/4 [pooch]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ------------------------------ --------- 3/4 [mne]\n",
            "   ---------------------------------------- 4/4 [mne]\n",
            "\n",
            "Successfully installed jinja2-3.1.6 mne-1.5.1 pooch-1.9.0 tqdm-4.67.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyedflib\n",
            "  Downloading pyedflib-0.1.42.tar.gz (2.3 MB)\n",
            "     ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
            "     ------------------ --------------------- 1.0/2.3 MB 30.5 MB/s eta 0:00:01\n",
            "     ------------------ --------------------- 1.0/2.3 MB 30.5 MB/s eta 0:00:01\n",
            "     ------------------ --------------------- 1.0/2.3 MB 30.5 MB/s eta 0:00:01\n",
            "     ------------------ --------------------- 1.0/2.3 MB 30.5 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 2.1/2.3 MB 1.9 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 2.1/2.3 MB 1.9 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 2.3/2.3 MB 1.5 MB/s  0:00:01\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: numpy>=1.9.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from pyedflib) (2.4.1)\n",
            "Building wheels for collected packages: pyedflib\n",
            "  Building wheel for pyedflib (pyproject.toml): started\n",
            "  Building wheel for pyedflib (pyproject.toml): finished with status 'error'\n",
            "Failed to build pyedflib\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Building wheel for pyedflib (pyproject.toml) did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [46 lines of output]\n",
            "      C:\\Users\\arshv\\AppData\\Local\\Temp\\pip-build-env-hxij4y72\\overlay\\Lib\\site-packages\\setuptools\\dist.py:765: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "      !!\n",
            "      \n",
            "              ********************************************************************************\n",
            "              Please consider removing the following classifiers in favor of a SPDX license expression:\n",
            "      \n",
            "              License :: OSI Approved :: BSD License\n",
            "      \n",
            "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
            "              ********************************************************************************\n",
            "      \n",
            "      !!\n",
            "        self._finalize_license_expression()\n",
            "      running bdist_wheel\n",
            "      running build\n",
            "      running build_py\n",
            "      creating build\\lib.win-amd64-cpython-313\\pyedflib\n",
            "      copying pyedflib\\edfreader.py -> build\\lib.win-amd64-cpython-313\\pyedflib\n",
            "      copying pyedflib\\edfwriter.py -> build\\lib.win-amd64-cpython-313\\pyedflib\n",
            "      copying pyedflib\\highlevel.py -> build\\lib.win-amd64-cpython-313\\pyedflib\n",
            "      copying pyedflib\\version.py -> build\\lib.win-amd64-cpython-313\\pyedflib\n",
            "      copying pyedflib\\__init__.py -> build\\lib.win-amd64-cpython-313\\pyedflib\n",
            "      creating build\\lib.win-amd64-cpython-313\\pyedflib\\_extensions\n",
            "      copying pyedflib\\_extensions\\__init__.py -> build\\lib.win-amd64-cpython-313\\pyedflib\\_extensions\n",
            "      creating build\\lib.win-amd64-cpython-313\\pyedflib\\data\n",
            "      copying pyedflib\\data\\_readers.py -> build\\lib.win-amd64-cpython-313\\pyedflib\\data\n",
            "      copying pyedflib\\data\\__init__.py -> build\\lib.win-amd64-cpython-313\\pyedflib\\data\n",
            "      creating build\\lib.win-amd64-cpython-313\\pyedflib\\tests\n",
            "      copying pyedflib\\tests\\test_doc.py -> build\\lib.win-amd64-cpython-313\\pyedflib\\tests\n",
            "      copying pyedflib\\tests\\test_edfreader.py -> build\\lib.win-amd64-cpython-313\\pyedflib\\tests\n",
            "      copying pyedflib\\tests\\test_edfwriter.py -> build\\lib.win-amd64-cpython-313\\pyedflib\\tests\n",
            "      copying pyedflib\\tests\\test_highlevel.py -> build\\lib.win-amd64-cpython-313\\pyedflib\\tests\n",
            "      copying pyedflib\\py.typed -> build\\lib.win-amd64-cpython-313\\pyedflib\n",
            "      copying pyedflib\\_extensions\\_pyedflib.pyi -> build\\lib.win-amd64-cpython-313\\pyedflib\\_extensions\n",
            "      copying pyedflib\\data\\test_generator.edf -> build\\lib.win-amd64-cpython-313\\pyedflib\\data\n",
            "      creating build\\lib.win-amd64-cpython-313\\pyedflib\\tests\\data\n",
            "      copying pyedflib\\tests\\data\\test_generator.edf -> build\\lib.win-amd64-cpython-313\\pyedflib\\tests\\data\n",
            "      copying pyedflib\\tests\\data\\test_legacy.edf -> build\\lib.win-amd64-cpython-313\\pyedflib\\tests\\data\n",
            "      copying pyedflib\\tests\\data\\test_subsecond.edf -> build\\lib.win-amd64-cpython-313\\pyedflib\\tests\\data\n",
            "      copying pyedflib\\tests\\data\\test_utf8.edf -> build\\lib.win-amd64-cpython-313\\pyedflib\\tests\\data\n",
            "      copying pyedflib\\tests\\data\\test_generator.bdf -> build\\lib.win-amd64-cpython-313\\pyedflib\\tests\\data\n",
            "      copying pyedflib\\tests\\data\\test_generator_datarec_generator_0_5.bdf -> build\\lib.win-amd64-cpython-313\\pyedflib\\tests\\data\n",
            "      copying pyedflib\\tests\\data\\test_generator_datarec_generator_2.bdf -> build\\lib.win-amd64-cpython-313\\pyedflib\\tests\\data\n",
            "      running build_clib\n",
            "      building 'c_edf' library\n",
            "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for pyedflib\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "error: failed-wheel-build-for-install\n",
            "\n",
            "× Failed to build installable wheels for some pyproject.toml based projects\n",
            "╰─> pyedflib\n",
            "ERROR: Could not find a version that satisfies the requirement wfdb-python (from versions: none)\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "ERROR: No matching distribution found for wfdb-python\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (2.20.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (26.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (6.33.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (2.32.5)\n",
            "Requirement already satisfied: setuptools in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (80.10.2)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (3.13.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10.1)\n",
            "Requirement already satisfied: pillow in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (12.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.46.3)\n",
            "Requirement already satisfied: rich in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.3.1)\n",
            "Requirement already satisfied: namex in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.24.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from scikit-learn) (2.4.1)\n",
            "Requirement already satisfied: scipy>=1.10.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from scikit-learn) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.3.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting plotly\n",
            "  Downloading plotly-6.5.2-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: matplotlib in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (3.10.8)\n",
            "Requirement already satisfied: seaborn in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (0.13.2)\n",
            "Collecting narwhals>=1.15.1 (from plotly)\n",
            "  Downloading narwhals-2.15.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from plotly) (26.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (2.4.1)\n",
            "Requirement already satisfied: pillow>=8 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (12.1.0)\n",
            "Requirement already satisfied: pyparsing>=3 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from seaborn) (3.0.0)\n",
            "Requirement already satisfied: tzdata in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading plotly-6.5.2-py3-none-any.whl (9.9 MB)\n",
            "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
            "   ------------ --------------------------- 3.1/9.9 MB 22.9 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 6.3/9.9 MB 16.3 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 9.2/9.9 MB 15.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 9.9/9.9 MB 14.5 MB/s  0:00:00\n",
            "Downloading narwhals-2.15.0-py3-none-any.whl (432 kB)\n",
            "Installing collected packages: narwhals, plotly\n",
            "\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   ---------------------------------------- 0/2 [narwhals]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   -------------------- ------------------- 1/2 [plotly]\n",
            "   ---------------------------------------- 2/2 [plotly]\n",
            "\n",
            "Successfully installed narwhals-2.15.0 plotly-6.5.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joblib in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (1.5.3)\n",
            "Packages installed! If you see any errors, please restart runtime and run this cell again.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install mne==1.5.1\n",
        "!pip install pyedflib\n",
        "!pip install wfdb-python\n",
        "!pip install tensorflow\n",
        "!pip install scikit-learn\n",
        "!pip install plotly matplotlib seaborn\n",
        "!pip install joblib\n",
        "\n",
        "# Restart runtime after installation\n",
        "print(\"Packages installed! If you see any errors, please restart runtime and run this cell again.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3XzPLtdyW0M",
        "outputId": "226b7cd8-e7c6-4f35-ee66-96a0cf72c6c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyedflib==0.1.30\n",
            "  Using cached pyEDFlib-0.1.30.tar.gz (1.7 MB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Getting requirements to build wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [168 lines of output]\n",
            "      Compiling pyedflib\\_extensions\\_pyedflib.pyx because it changed.\n",
            "      [1/1] Cythonizing pyedflib\\_extensions\\_pyedflib.pyx\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "      \n",
            "      #from c_edf cimport *\n",
            "      import locale\n",
            "      import os\n",
            "      import warnings\n",
            "      cimport c_edf\n",
            "              ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:25:8: 'c_edf.pxd' not found\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "          needed according the montage and filter settings, then display the data.\n",
            "      \n",
            "          \"\"\"\n",
            "      \n",
            "      \n",
            "          cdef c_edf.edf_hdr_struct hdr\n",
            "               ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:137:9: 'edf_hdr_struct' is not a type identifier\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "      \n",
            "      cpdef int set_technician(int handle, char *technician):\n",
            "          return c_edf.edf_set_technician(handle, technician)\n",
            "      \n",
            "      cdef class EdfAnnotation:\n",
            "          cdef c_edf.edf_annotation_struct annotation\n",
            "               ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:457:9: 'edf_annotation_struct' is not a type identifier\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "              self.file_name = file_name\n",
            "      \n",
            "              return self.check_open_ok(result)\n",
            "      \n",
            "          def read_annotation(self):\n",
            "              cdef c_edf.edf_annotation_struct annot\n",
            "                   ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:212:13: 'edf_annotation_struct' is not a type identifier\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "                  return output_buf.value\n",
            "              else:\n",
            "                  output_buf_size = needed\n",
            "      \n",
            "      def lib_version():\n",
            "          return c_edf.edflib_version()\n",
            "                      ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:118:16: cimported module has no attribute 'edflib_version'\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "                      raise e\n",
            "      \n",
            "      \n",
            "          def __dealloc__(self):\n",
            "              if self.hdr.handle >= 0:\n",
            "                  c_edf.edfclose_file(self.hdr.handle)\n",
            "                       ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:171:17: cimported module has no attribute 'edfclose_file'\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "          def open(self, file_name, annotations_mode=EDFLIB_READ_ALL_ANNOTATIONS, check_file_size=EDFLIB_CHECK_FILE_SIZE):\n",
            "              \"\"\"\n",
            "              open(file_name, annotations_mode, check_file_size)\n",
            "              \"\"\"\n",
            "              file_name_str = file_name.encode('utf8','strict')\n",
            "              result = c_edf.edfopen_file_readonly(file_name_str, &self.hdr, annotations_mode, check_file_size)\n",
            "                            ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:205:22: cimported module has no attribute 'edfopen_file_readonly'\n",
            "      \n",
            "      Error compiling Cython file:\n",
            "      ------------------------------------------------------------\n",
            "      ...\n",
            "          def open(self, file_name, annotations_mode=EDFLIB_READ_ALL_ANNOTATIONS, check_file_size=EDFLIB_CHECK_FILE_SIZE):\n",
            "              \"\"\"\n",
            "              open(file_name, annotations_mode, check_file_size)\n",
            "              \"\"\"\n",
            "              file_name_str = file_name.encode('utf8','strict')\n",
            "              result = c_edf.edfopen_file_readonly(file_name_str, &self.hdr, annotations_mode, check_file_size)\n",
            "                            ^\n",
            "      ------------------------------------------------------------\n",
            "      pyedflib\\_extensions\\_pyedflib.pyx:205:22: Compiler crash in AnalyseExpressionsTransform\n",
            "      \n",
            "      ModuleNode.body = StatListNode(_pyedflib.pyx:6:0)\n",
            "      StatListNode.stats[20] = StatListNode(_pyedflib.pyx:120:0)\n",
            "      StatListNode.stats[0] = CClassDefNode(_pyedflib.pyx:120:0,\n",
            "          as_name = 'CyEdfReader',\n",
            "          class_name = 'CyEdfReader',\n",
            "          doc = '\\n    This provides a simple interface to read EDF, EDF+, and probably is ok with\\n    BDF and BDF+ files\\n    Note that edflib.c is encapsulated so there is no direct access to the file\\n    from here unless I add a raw interface or something\\n\\n    EDF/BDF+ files are arranged into N signals sampled at rate Fs. The data is actually stored in chunks called    \"datarecords\" which have a file specific size.\\n\\n    A typical way to use this to read an EEG file would be to choose a certain\\n    number of seconds per page to display. Then figureout how many data records\\n    that is. Then read in that many data records at a time. Transform the data as\\n    needed according the montage and filter settings, then display the data.\\n\\n    ',\n",
            "          module_name = '',\n",
            "          punycode_class_name = 'CyEdfReader',\n",
            "          visibility = 'private')\n",
            "      CClassDefNode.body = StatListNode(_pyedflib.pyx:121:4)\n",
            "      StatListNode.stats[6] = DefNode(_pyedflib.pyx:200:4,\n",
            "          doc = '\\n        open(file_name, annotations_mode, check_file_size)\\n        ',\n",
            "          is_cyfunction = True,\n",
            "          modifiers = [...]/0,\n",
            "          name = 'open',\n",
            "          np_args_idx = [...]/0,\n",
            "          num_required_args = 2,\n",
            "          outer_attrs = [...]/2,\n",
            "          py_wrapper_required = True,\n",
            "          reqd_kw_flags_cname = '0',\n",
            "          used = True)\n",
            "      File 'ExprNodes.py', line 6078, in infer_type: SimpleCallNode(_pyedflib.pyx:205:44,\n",
            "          result_is_used = True,\n",
            "          use_managed_ref = True)\n",
            "      File 'ExprNodes.py', line 7806, in infer_type: AttributeNode(_pyedflib.pyx:205:22,\n",
            "          attribute = 'edfopen_file_readonly',\n",
            "          is_attribute = 1,\n",
            "          needs_none_check = True,\n",
            "          result_is_used = True,\n",
            "          use_managed_ref = True)\n",
            "      \n",
            "      Compiler crash traceback from this point on:\n",
            "        File \"C:\\Users\\arshv\\AppData\\Local\\Temp\\pip-build-env-ek8co2sl\\overlay\\Lib\\site-packages\\Cython\\Compiler\\ExprNodes.py\", line 7806, in infer_type\n",
            "          if node.entry.type and node.entry.type.is_cfunction:\n",
            "             ^^^^^^^^^^^^^^^\n",
            "      AttributeError: 'NoneType' object has no attribute 'type'\n",
            "      Traceback (most recent call last):\n",
            "        File \u001b[35m\"C:\\ASK_Main\\ASK_College_Tpoly\\DHS_AC_MASTERS\\DHS\\Code\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "          \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
            "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\ASK_Main\\ASK_College_Tpoly\\DHS_AC_MASTERS\\DHS\\Code\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
            "          json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
            "                                   \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\ASK_Main\\ASK_College_Tpoly\\DHS_AC_MASTERS\\DHS\\Code\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
            "          return hook(config_settings)\n",
            "        File \u001b[35m\"C:\\Users\\arshv\\AppData\\Local\\Temp\\pip-build-env-ek8co2sl\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m333\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
            "          return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
            "                 \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\arshv\\AppData\\Local\\Temp\\pip-build-env-ek8co2sl\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
            "          \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
            "          \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\arshv\\AppData\\Local\\Temp\\pip-build-env-ek8co2sl\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
            "          \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
            "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m266\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\arshv\\AppData\\Local\\Temp\\pip-build-env-ek8co2sl\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\"\u001b[0m, line \u001b[35m1153\u001b[0m, in \u001b[35mcythonize\u001b[0m\n",
            "          \u001b[31mcythonize_one\u001b[0m\u001b[1;31m(*args)\u001b[0m\n",
            "          \u001b[31m~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\arshv\\AppData\\Local\\Temp\\pip-build-env-ek8co2sl\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\"\u001b[0m, line \u001b[35m1297\u001b[0m, in \u001b[35mcythonize_one\u001b[0m\n",
            "          raise CompileError(None, pyx_file)\n",
            "      \u001b[1;35mCython.Compiler.Errors.CompileError\u001b[0m: \u001b[35mpyedflib\\_extensions\\_pyedflib.pyx\u001b[0m\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× Getting requirements to build wheel did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (2.20.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (26.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (6.33.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (2.32.5)\n",
            "Requirement already satisfied: setuptools in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (80.10.2)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (3.13.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10.1)\n",
            "Requirement already satisfied: pillow in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (12.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.46.3)\n",
            "Requirement already satisfied: rich in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.3.1)\n",
            "Requirement already satisfied: namex in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.24.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from scikit-learn) (2.4.1)\n",
            "Requirement already satisfied: scipy>=1.10.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from scikit-learn) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.3.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (3.10.8)\n",
            "Requirement already satisfied: seaborn in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (2.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (12.1.0)\n",
            "Requirement already satisfied: pyparsing>=3 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from seaborn) (3.0.0)\n",
            "Requirement already satisfied: tzdata in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (1.17.0)\n",
            "Requirement already satisfied: numpy in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (2.4.1)\n",
            "Requirement already satisfied: pandas in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (3.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joblib in c:\\ask_main\\ask_college_tpoly\\dhs_ac_masters\\dhs\\code\\.venv\\lib\\site-packages (1.5.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pyedflib'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix, roc_auc_score, roc_curve\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyedflib\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pyedflib'"
          ]
        }
      ],
      "source": [
        "!pip install pyedflib==0.1.30\n",
        "!pip install tensorflow\n",
        "!pip install scikit-learn\n",
        "!pip install matplotlib seaborn\n",
        "!pip install scipy numpy pandas\n",
        "!pip install joblib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pyedflib\n",
        "import os\n",
        "import requests\n",
        "from scipy import signal\n",
        "from scipy.stats import skew, kurtosis\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"PyEDFlib version: {pyedflib.version.version}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNbcQkd4AZoB",
        "outputId": "1c462003-1dd1-4244-a421-4bb97ca5e3d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: BeautifulSoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from BeautifulSoup4) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from BeautifulSoup4) (4.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install BeautifulSoup4\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IcpNyYA0Gbp",
        "outputId": "9554badc-85e7-41fd-c76e-e61904121192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Fetching dataset file list...\n",
            "✅ Found 24 patient folders.\n",
            "\n",
            "📂 Downloading 43 files from chb01/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Folder chb01:   2%|▏         | 1/43 [00:00<00:07,  5.86file/s]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm  # Great for Colab progress bars\n",
        "\n",
        "def download_full_chb_mit_dataset():\n",
        "    \"\"\"Download the full CHB-MIT dataset from PhysioNet\"\"\"\n",
        "    base_url = \"https://physionet.org/files/chbmit/1.0.0/\"\n",
        "    save_dir = \"chb-mit-data\"\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    print(\"🔍 Fetching dataset file list...\")\n",
        "    try:\n",
        "        response = requests.get(base_url)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to connect to PhysioNet: {e}\")\n",
        "        return\n",
        "\n",
        "    # Extract all patient folder links\n",
        "    patient_folders = [\n",
        "        link.get(\"href\") for link in soup.find_all(\"a\")\n",
        "        if link.get(\"href\") and link.get(\"href\").startswith(\"chb\")\n",
        "    ]\n",
        "\n",
        "    print(f\"✅ Found {len(patient_folders)} patient folders.\\n\")\n",
        "\n",
        "    for folder in patient_folders:\n",
        "        folder_url = base_url + folder\n",
        "        patient_dir = os.path.join(save_dir, folder.strip(\"/\"))\n",
        "        os.makedirs(patient_dir, exist_ok=True)\n",
        "\n",
        "        folder_response = requests.get(folder_url)\n",
        "        folder_soup = BeautifulSoup(folder_response.text, \"html.parser\")\n",
        "\n",
        "        # Filter for .edf and .txt files\n",
        "        files = [\n",
        "            link.get(\"href\") for link in folder_soup.find_all(\"a\")\n",
        "            if link.get(\"href\") and (link.get(\"href\").endswith(\".edf\") or link.get(\"href\").endswith(\".txt\"))\n",
        "        ]\n",
        "\n",
        "        print(f\"📂 Downloading {len(files)} files from {folder}...\")\n",
        "\n",
        "        for file_name in tqdm(files, desc=f\"Folder {folder.strip('/')}\", unit=\"file\"):\n",
        "            file_url = folder_url + file_name\n",
        "            local_path = os.path.join(patient_dir, file_name)\n",
        "\n",
        "            if os.path.exists(local_path):\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                r = requests.get(file_url, stream=True)\n",
        "                with open(local_path, \"wb\") as f:\n",
        "                    for chunk in r.iter_content(chunk_size=8192):\n",
        "                        if chunk:\n",
        "                            f.write(chunk)\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error downloading {file_name}: {e}\")\n",
        "\n",
        "    print(\"\\n🎉 Full CHB-MIT Dataset Download Completed!\")\n",
        "\n",
        "# Run downloader\n",
        "download_full_chb_mit_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSMVHk2-1hUz"
      },
      "outputs": [],
      "source": [
        "class EEGLoader:\n",
        "    def __init__(self, target_sampling_rate=256):\n",
        "        self.target_fs = target_sampling_rate\n",
        "\n",
        "    def load_edf_file(self, file_path):\n",
        "        \"\"\"Load EDF file using pyedflib\"\"\"\n",
        "        try:\n",
        "            with pyedflib.EdfReader(file_path) as f:\n",
        "                n_channels = f.signals_in_file\n",
        "                signal_labels = f.getSignalLabels()\n",
        "                sample_frequency = f.getSampleFrequency(0)\n",
        "\n",
        "                # Read all signals\n",
        "                signals = []\n",
        "                for i in range(n_channels):\n",
        "                    signal_data = f.readSignal(i)\n",
        "                    signals.append(signal_data)\n",
        "\n",
        "                return {\n",
        "                    'data': np.array(signals),\n",
        "                    'sample_frequency': sample_frequency,\n",
        "                    'channel_names': signal_labels,\n",
        "                    'n_channels': n_channels,\n",
        "                    'duration': len(signals[0]) / sample_frequency\n",
        "                }\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_path}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def apply_filters(self, data, sample_freq):\n",
        "        \"\"\"Apply basic filtering\"\"\"\n",
        "        filtered_data = []\n",
        "\n",
        "        for channel_data in data:\n",
        "            # Apply bandpass filter (0.5-50 Hz)\n",
        "            nyquist = sample_freq / 2\n",
        "            low_freq = 0.5 / nyquist\n",
        "            high_freq = min(50.0, nyquist * 0.95) / nyquist\n",
        "\n",
        "            if low_freq < 1.0 and high_freq < 1.0:\n",
        "                b, a = signal.butter(4, [low_freq, high_freq], btype='band')\n",
        "                filtered_signal = signal.filtfilt(b, a, channel_data)\n",
        "            else:\n",
        "                filtered_signal = channel_data\n",
        "\n",
        "            filtered_data.append(filtered_signal)\n",
        "\n",
        "        return np.array(filtered_data)\n",
        "\n",
        "    def resample_data(self, data, original_fs, target_fs):\n",
        "        \"\"\"Resample data to target frequency\"\"\"\n",
        "        if original_fs == target_fs:\n",
        "            return data\n",
        "\n",
        "        resampled_data = []\n",
        "        for channel_data in data:\n",
        "            resampled_signal = signal.resample(\n",
        "                channel_data,\n",
        "                int(len(channel_data) * target_fs / original_fs)\n",
        "            )\n",
        "            resampled_data.append(resampled_signal)\n",
        "\n",
        "        return np.array(resampled_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTm8t_f01p4v"
      },
      "outputs": [],
      "source": [
        "def parse_seizure_summary(summary_file):\n",
        "    \"\"\"Parse the seizure summary file to extract seizure times\"\"\"\n",
        "    seizure_info = {}\n",
        "\n",
        "    if not os.path.exists(summary_file):\n",
        "        print(f\"Summary file not found: {summary_file}\")\n",
        "        return {}\n",
        "\n",
        "    try:\n",
        "        with open(summary_file, 'r') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Extract file information and seizure times\n",
        "        lines = content.split('\\n')\n",
        "        current_file = None\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line.startswith('File Name:'):\n",
        "                current_file = line.split(':')[-1].strip()\n",
        "                if current_file not in seizure_info:\n",
        "                    seizure_info[current_file] = []\n",
        "\n",
        "            elif line.startswith('Seizure Start Time:') and current_file:\n",
        "                try:\n",
        "                    start_time = int(line.split(':')[-1].strip().split()[0])\n",
        "                    seizure_info[current_file].append({'start': start_time})\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            elif line.startswith('Seizure End Time:') and current_file:\n",
        "                if seizure_info[current_file]:\n",
        "                    try:\n",
        "                        end_time = int(line.split(':')[-1].strip().split()[0])\n",
        "                        seizure_info[current_file][-1]['end'] = end_time\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "        return seizure_info\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing summary file: {str(e)}\")\n",
        "        return {}\n",
        "\n",
        "# Parse seizure information\n",
        "seizure_data = parse_seizure_summary('chb-mit-data/chb01-summary.txt')\n",
        "print(\"Seizure information:\")\n",
        "for file, seizures in seizure_data.items():\n",
        "    print(f\"{file}: {len(seizures)} seizures - {seizures}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVTteXET1wwb"
      },
      "outputs": [],
      "source": [
        "class FeatureExtractor:\n",
        "    def __init__(self, window_duration=4, sampling_rate=256):\n",
        "        self.window_duration = window_duration\n",
        "        self.sampling_rate = sampling_rate\n",
        "        self.window_samples = int(window_duration * sampling_rate)\n",
        "\n",
        "    def extract_time_features(self, signal_data):\n",
        "        \"\"\"Extract time domain features\"\"\"\n",
        "        features = [\n",
        "            np.mean(signal_data),\n",
        "            np.std(signal_data),\n",
        "            np.var(signal_data),\n",
        "            skew(signal_data),\n",
        "            kurtosis(signal_data),\n",
        "            np.max(signal_data) - np.min(signal_data),  # Peak-to-peak\n",
        "            np.sqrt(np.mean(signal_data**2)),  # RMS\n",
        "            np.mean(np.abs(np.diff(signal_data)))  # Mean absolute deviation\n",
        "        ]\n",
        "        return features\n",
        "\n",
        "    def extract_frequency_features(self, signal_data):\n",
        "        \"\"\"Extract frequency domain features\"\"\"\n",
        "        try:\n",
        "            freqs, psd = signal.welch(signal_data, self.sampling_rate, nperseg=min(256, len(signal_data)//4))\n",
        "\n",
        "            # Band power features\n",
        "            delta_power = np.sum(psd[(freqs >= 0.5) & (freqs <= 4)])\n",
        "            theta_power = np.sum(psd[(freqs >= 4) & (freqs <= 8)])\n",
        "            alpha_power = np.sum(psd[(freqs >= 8) & (freqs <= 13)])\n",
        "            beta_power = np.sum(psd[(freqs >= 13) & (freqs <= 30)])\n",
        "            gamma_power = np.sum(psd[(freqs >= 30) & (freqs <= 50)])\n",
        "\n",
        "            # Spectral features\n",
        "            spectral_centroid = np.sum(freqs * psd) / np.sum(psd)\n",
        "            spectral_bandwidth = np.sqrt(np.sum(((freqs - spectral_centroid) ** 2) * psd) / np.sum(psd))\n",
        "\n",
        "            return [delta_power, theta_power, alpha_power, beta_power, gamma_power,\n",
        "                   spectral_centroid, spectral_bandwidth]\n",
        "        except:\n",
        "            return [0] * 7\n",
        "\n",
        "    def extract_features_from_window(self, window):\n",
        "        \"\"\"Extract all features from a window\"\"\"\n",
        "        all_features = []\n",
        "\n",
        "        for channel_idx in range(window.shape[0]):\n",
        "            signal_data = window[channel_idx, :]\n",
        "\n",
        "            # Time domain features\n",
        "            time_features = self.extract_time_features(signal_data)\n",
        "\n",
        "            # Frequency domain features\n",
        "            freq_features = self.extract_frequency_features(signal_data)\n",
        "\n",
        "            # Combine features for this channel\n",
        "            channel_features = time_features + freq_features\n",
        "            all_features.extend(channel_features)\n",
        "\n",
        "        return np.array(all_features)\n",
        "\n",
        "    def create_windows_and_labels(self, eeg_data, sampling_rate, seizure_times=None, prediction_horizon=300):\n",
        "        \"\"\"Create sliding windows with labels\"\"\"\n",
        "        n_channels, n_samples = eeg_data.shape\n",
        "        step_size = self.window_samples // 2  # 50% overlap\n",
        "\n",
        "        X, y = [], []\n",
        "\n",
        "        for start_idx in range(0, n_samples - self.window_samples + 1, step_size):\n",
        "            end_idx = start_idx + self.window_samples\n",
        "            window = eeg_data[:, start_idx:end_idx]\n",
        "\n",
        "            # Extract features\n",
        "            features = self.extract_features_from_window(window)\n",
        "\n",
        "            # Determine label\n",
        "            current_time_sec = start_idx / sampling_rate\n",
        "\n",
        "            is_preictal = False\n",
        "            if seizure_times:\n",
        "                for seizure in seizure_times:\n",
        "                    if 'start' in seizure:\n",
        "                        seizure_start = seizure['start']\n",
        "                        # Check if current window is within prediction horizon before seizure\n",
        "                        if (seizure_start - prediction_horizon) <= current_time_sec <= seizure_start:\n",
        "                            is_preictal = True\n",
        "                            break\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(1 if is_preictal else 0)\n",
        "\n",
        "        return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gZdUD3P15k2"
      },
      "outputs": [],
      "source": [
        "def load_and_process_all_data():\n",
        "    \"\"\"Load and process all EDF files\"\"\"\n",
        "    loader = EEGLoader(target_sampling_rate=256)\n",
        "    extractor = FeatureExtractor(window_duration=4, sampling_rate=256)\n",
        "\n",
        "    all_X, all_y = [], []\n",
        "\n",
        "    # Get list of EDF files\n",
        "    edf_files = [f for f in os.listdir('chb-mit-data') if f.endswith('.edf')]\n",
        "    print(f\"Found {len(edf_files)} EDF files\")\n",
        "\n",
        "    for edf_file in edf_files:\n",
        "        file_path = f'chb-mit-data/{edf_file}'\n",
        "        print(f\"\\nProcessing {edf_file}...\")\n",
        "\n",
        "        # Load EEG data\n",
        "        eeg_data = loader.load_edf_file(file_path)\n",
        "        if eeg_data is None:\n",
        "            continue\n",
        "\n",
        "        print(f\"  - Channels: {eeg_data['n_channels']}\")\n",
        "        print(f\"  - Sampling rate: {eeg_data['sample_frequency']} Hz\")\n",
        "        print(f\"  - Duration: {eeg_data['duration']:.2f} seconds\")\n",
        "\n",
        "        # Apply preprocessing\n",
        "        print(\"  - Applying filters...\")\n",
        "        filtered_data = loader.apply_filters(eeg_data['data'], eeg_data['sample_frequency'])\n",
        "\n",
        "        # Resample if needed\n",
        "        if eeg_data['sample_frequency'] != 256:\n",
        "            print(\"  - Resampling...\")\n",
        "            filtered_data = loader.resample_data(\n",
        "                filtered_data, eeg_data['sample_frequency'], 256\n",
        "            )\n",
        "\n",
        "        # Get seizure times for this file\n",
        "        seizure_times = seizure_data.get(edf_file, [])\n",
        "\n",
        "        # Create windows and labels\n",
        "        print(\"  - Creating windows...\")\n",
        "        X, y = extractor.create_windows_and_labels(\n",
        "            filtered_data, 256, seizure_times, prediction_horizon=300\n",
        "        )\n",
        "\n",
        "        print(f\"  - Created {len(X)} windows\")\n",
        "        print(f\"  - Features per window: {X.shape[1] if len(X) > 0 else 0}\")\n",
        "        print(f\"  - Positive samples (preictal): {np.sum(y)}\")\n",
        "        print(f\"  - Negative samples (interictal): {len(y) - np.sum(y)}\")\n",
        "\n",
        "        if len(X) > 0:\n",
        "            all_X.append(X)\n",
        "            all_y.append(y)\n",
        "\n",
        "    if len(all_X) == 0:\n",
        "        print(\"No data processed successfully!\")\n",
        "        return None, None\n",
        "\n",
        "    # Combine all data\n",
        "    X_combined = np.vstack(all_X)\n",
        "    y_combined = np.hstack(all_y)\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"TOTAL DATASET SUMMARY\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"Total windows: {len(X_combined)}\")\n",
        "    print(f\"Features per window: {X_combined.shape[1]}\")\n",
        "    print(f\"Positive samples (preictal): {np.sum(y_combined)} ({np.mean(y_combined)*100:.1f}%)\")\n",
        "    print(f\"Negative samples (interictal): {len(y_combined) - np.sum(y_combined)} ({(1-np.mean(y_combined))*100:.1f}%)\")\n",
        "\n",
        "    return X_combined, y_combined\n",
        "\n",
        "# Load and process all data\n",
        "X, y = load_and_process_all_data()\n",
        "\n",
        "if X is None:\n",
        "    print(\"Creating synthetic data for demonstration...\")\n",
        "    # Create synthetic data for demonstration\n",
        "    np.random.seed(42)\n",
        "    n_samples = 1000\n",
        "    n_features = 23 * 15  # 23 channels * 15 features per channel\n",
        "\n",
        "    X = np.random.randn(n_samples, n_features)\n",
        "    y = np.random.choice([0, 1], size=n_samples, p=[0.9, 0.1])  # 10% positive samples\n",
        "\n",
        "    print(f\"Created synthetic dataset:\")\n",
        "    print(f\"- Samples: {len(X)}\")\n",
        "    print(f\"- Features: {X.shape[1]}\")\n",
        "    print(f\"- Positive samples: {np.sum(y)}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GdPT6SI5z3b"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Balance dataset\n",
        "def balance_dataset(X, y, max_samples=5000):\n",
        "    \"\"\"Balance dataset and limit size for training efficiency\"\"\"\n",
        "\n",
        "    X_positive = X[y == 1]\n",
        "    X_negative = X[y == 0]\n",
        "\n",
        "    print(f\"Original dataset:\")\n",
        "    print(f\"- Positive samples: {len(X_positive)}\")\n",
        "    print(f\"- Negative samples: {len(X_negative)}\")\n",
        "\n",
        "    # If we have positive samples, balance the dataset\n",
        "    if len(X_positive) > 0:\n",
        "        # Determine target size\n",
        "        target_positive = min(len(X_positive) * 3, max_samples // 4)  # Up to 25% positive\n",
        "        target_negative = min(target_positive * 3, len(X_negative))\n",
        "\n",
        "        # Sample from each class\n",
        "        if len(X_positive) < target_positive:\n",
        "            # Oversample positive class\n",
        "            X_pos_balanced = resample(X_positive, n_samples=target_positive, random_state=42, replace=True)\n",
        "        else:\n",
        "            X_pos_balanced = resample(X_positive, n_samples=target_positive, random_state=42, replace=False)\n",
        "\n",
        "        X_neg_balanced = resample(X_negative, n_samples=target_negative, random_state=42, replace=False)\n",
        "\n",
        "        # Combine\n",
        "        X_balanced = np.vstack([X_neg_balanced, X_pos_balanced])\n",
        "        y_balanced = np.hstack([np.zeros(target_negative), np.ones(target_positive)])\n",
        "    else:\n",
        "        # No positive samples - create some synthetic ones\n",
        "        print(\"No positive samples found. Creating synthetic positive samples...\")\n",
        "        target_samples = min(max_samples, len(X_negative))\n",
        "        target_positive = target_samples // 10  # 10% positive\n",
        "        target_negative = target_samples - target_positive\n",
        "\n",
        "        # Sample negative class\n",
        "        X_neg_balanced = resample(X_negative, n_samples=target_negative, random_state=42, replace=False)\n",
        "\n",
        "        # Create synthetic positive samples (add noise to random negative samples)\n",
        "        synthetic_indices = np.random.choice(len(X_negative), target_positive, replace=True)\n",
        "        X_pos_balanced = X_negative[synthetic_indices] + np.random.normal(0, 0.1, (target_positive, X.shape[1]))\n",
        "\n",
        "        # Combine\n",
        "        X_balanced = np.vstack([X_neg_balanced, X_pos_balanced])\n",
        "        y_balanced = np.hstack([np.zeros(target_negative), np.ones(target_positive)])\n",
        "\n",
        "    print(f\"Balanced dataset:\")\n",
        "    print(f\"- Total samples: {len(X_balanced)}\")\n",
        "    print(f\"- Positive samples: {np.sum(y_balanced)} ({np.mean(y_balanced)*100:.1f}%)\")\n",
        "    print(f\"- Negative samples: {len(y_balanced) - np.sum(y_balanced)} ({(1-np.mean(y_balanced))*100:.1f}%)\")\n",
        "\n",
        "    return X_balanced, y_balanced\n",
        "\n",
        "# Balance the dataset\n",
        "X_balanced, y_balanced = balance_dataset(X, y)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_balanced)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain/Test Split:\")\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0sywYuN5_R7"
      },
      "outputs": [],
      "source": [
        "def build_lstm_model(input_shape):\n",
        "    \"\"\"Build LSTM model\"\"\"\n",
        "    model = Sequential([\n",
        "        tf.keras.layers.Reshape((input_shape[0], 1), input_shape=input_shape),\n",
        "        LSTM(64, return_sequences=True, dropout=0.2),\n",
        "        BatchNormalization(),\n",
        "        LSTM(32, return_sequences=False, dropout=0.2),\n",
        "        BatchNormalization(),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'precision', 'recall']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build model\n",
        "print(\"Building LSTM model...\")\n",
        "model = build_lstm_model((X_train.shape[1],))\n",
        "model.summary()\n",
        "\n",
        "# Train model\n",
        "print(\"\\nTraining model...\")\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-7)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8e6842d"
      },
      "source": [
        "## Understanding EEG and Data Collection\n",
        "\n",
        "**What is EEG?**\n",
        "\n",
        "Electroencephalography (EEG) is a non-invasive neurophysiological method that measures and records the electrical activity of the brain. This activity is generated by the synchronized firing of large groups of neurons, particularly in the cerebral cortex. Electrodes placed on the scalp detect these small electrical potentials, which are then amplified and recorded as waveforms. These waveforms reflect the brain's state of activity and can be used to diagnose various neurological conditions, including epilepsy.\n",
        "\n",
        "**Practical Workflow Related to EEG Data Collection:**\n",
        "\n",
        "The practical workflow for EEG data collection typically involves several key steps:\n",
        "\n",
        "1.  **Preparation:**\n",
        "    *   **Patient/Subject Preparation:** The individual undergoing the EEG needs to be prepared. This might involve washing their hair to ensure good electrode contact and explaining the procedure to them to reduce anxiety.\n",
        "    *   **Equipment Setup:** The EEG machine, electrodes, and conductive gel or paste are prepared. The recording environment should be quiet and free from electrical interference.\n",
        "\n",
        "2.  **Electrode Placement:**\n",
        "    *   Electrodes are carefully placed on the scalp according to a standardized system, most commonly the 10-20 system. This system ensures that electrodes are placed at specific locations relative to anatomical landmarks on the skull, allowing for consistent recording across individuals.\n",
        "    *   Conductive gel or paste is applied to each electrode to ensure good electrical contact with the scalp and minimize impedance (resistance).\n",
        "\n",
        "3.  **Recording:**\n",
        "    *   Once the electrodes are in place and the impedance is checked and within acceptable limits, the EEG recording begins.\n",
        "    *   The recording typically involves different states, such as eyes closed, eyes open, hyperventilation, and photic stimulation (flashing lights), to elicit various brain responses.\n",
        "    *   The duration of the recording can vary depending on the clinical question, ranging from 20-30 minutes for routine EEGs to several hours or even days for long-term monitoring.\n",
        "\n",
        "4.  **Monitoring:**\n",
        "    *   Throughout the recording, a technician or clinician monitors the EEG waveforms on a computer screen to ensure data quality and identify any abnormal activity.\n",
        "    *   Annotations are often added to the recording to mark events like artifacts (e.g., eye blinks, muscle movements), changes in the patient's state, or the occurrence of seizures.\n",
        "\n",
        "5.  **Data Storage:**\n",
        "    *   The recorded EEG data is saved electronically, often in standardized formats like EDF (European Data Format), which is used in this project.\n",
        "\n",
        "## Importance of This Project\n",
        "\n",
        "This project, focused on epileptic seizure prediction using EEG, holds significant importance for several reasons:\n",
        "\n",
        "1.  **Improving Patient Lives:** Seizure prediction can dramatically improve the lives of individuals with epilepsy by providing them with advance warning of an impending seizure. This allows them to take safety precautions, seek a safe environment, or administer rescue medication, potentially preventing injuries and reducing the impact of seizures on their daily activities.\n",
        "\n",
        "2.  **Enhanced Treatment Strategies:** Accurate seizure prediction can inform and improve treatment strategies. It can help clinicians determine the effectiveness of medications, identify seizure triggers, and potentially personalize treatment plans.\n",
        "\n",
        "3.  **Reducing Seizure Burden:** By enabling proactive measures, seizure prediction can contribute to a reduction in the frequency and severity of seizures over time.\n",
        "\n",
        "4.  **Advancing Epilepsy Research:** This project contributes to the ongoing research in epilepsy by exploring the feasibility of using machine learning techniques to analyze complex EEG data for predictive purposes. The insights gained can lead to a better understanding of the preictal state and the underlying mechanisms of seizures.\n",
        "\n",
        "5.  **Developing Wearable and Implantable Devices:** Successful seizure prediction algorithms are crucial for the development of wearable or implantable devices that can monitor EEG in real-time and alert patients or caregivers to an impending seizure.\n",
        "\n",
        "6.  **Potential for Broader Applications:** The techniques and methodologies developed in this project for analyzing time-series data and building predictive models can potentially be applied to other neurological conditions or physiological signals.\n",
        "\n",
        "In summary, this project is a step towards developing a valuable tool that could empower individuals with epilepsy, improve clinical care, and contribute to advancements in neuroscience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL5QPUH8-Kfx"
      },
      "outputs": [],
      "source": [
        "print(f\"\\n{'='*50}\")\n",
        "print(\"MODEL EVALUATION\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred_proba = model.predict(X_test, verbose=0).flatten()\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate metrics\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(f\"\\nKey Metrics:\")\n",
        "print(f\"Sensitivity (Recall): {sensitivity:.3f}\")\n",
        "print(f\"Specificity: {specificity:.3f}\")\n",
        "print(f\"AUC-ROC: {auc_score:.3f}\")\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'LSTM Model (AUC = {auc_score:.3f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - LSTM Seizure Prediction')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save model\n",
        "model.save('lstm_seizure_model.h5')\n",
        "import joblib\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(\"IMPLEMENTATION COMPLETED!\")\n",
        "print(f\"{'='*50}\")\n",
        "print(\"Model and scaler saved successfully!\")\n",
        "print(\"You can now use these for real-time seizure prediction.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc66994b"
      },
      "source": [
        "## Project Overview: Epileptic Seizure Prediction using EEG\n",
        "\n",
        "This project demonstrates a workflow for predicting epileptic seizures using Electroencephalography (EEG) data. The process involves loading raw EEG data, preprocessing it, extracting relevant features, and training a machine learning model to classify EEG segments as either \"interictal\" (normal state) or \"preictal\" (state preceding a seizure).\n",
        "\n",
        "Here's a breakdown of the key steps:\n",
        "\n",
        "1.  **Setup and Library Installation**:\n",
        "    *   Installs necessary Python libraries for EEG data processing (MNE, PyEDFlib, WFDB), numerical operations (NumPy, SciPy), data manipulation (Pandas), visualization (Matplotlib, Seaborn, Plotly), and machine learning (TensorFlow, Scikit-learn, Joblib).\n",
        "\n",
        "2.  **Data Acquisition**:\n",
        "    *   Downloads a sample of the CHB-MIT Scalp EEG Database, a publicly available dataset containing EEG recordings from pediatric subjects with intractable seizures.\n",
        "    *   The `download_chb_mit_sample` function fetches specific EDF (European Data Format) files and a summary file containing seizure onset and offset times.\n",
        "\n",
        "3.  **Data Loading and Preprocessing**:\n",
        "    *   The `EEGLoader` class handles loading and initial processing of the EDF files.\n",
        "    *   It reads the EEG signals, sampling frequency, and channel labels using `pyedflib`.\n",
        "    *   Basic filtering (bandpass) is applied to the raw data to remove unwanted frequencies.\n",
        "    *   Data is resampled to a target sampling rate (256 Hz in this case) to ensure consistency across different recordings.\n",
        "\n",
        "4.  **Seizure Annotation Parsing**:\n",
        "    *   The `parse_seizure_summary` function extracts seizure start and end times from the downloaded summary text file.\n",
        "    *   This information is crucial for labeling the EEG data segments during the feature extraction phase.\n",
        "\n",
        "5.  **Feature Extraction and Windowing**:\n",
        "    *   The `FeatureExtractor` class divides the continuous EEG data into smaller, overlapping windows.\n",
        "    *   For each window, it calculates a set of time-domain (mean, standard deviation, skewness, kurtosis, etc.) and frequency-domain (band power in different frequency bands, spectral centroid, spectral bandwidth) features.\n",
        "    *   Each window is labeled based on whether it falls within a defined \"preictal\" period (e.g., 300 seconds before a seizure) or is considered \"interictal\".\n",
        "\n",
        "6.  **Dataset Preparation**:\n",
        "    *   The `load_and_process_all_data` function orchestrates the loading, preprocessing, feature extraction, and windowing for all specified EDF files.\n",
        "    *   The extracted features (`X`) and corresponding labels (`y`) are combined into a single dataset.\n",
        "    *   The `balance_dataset` function addresses the class imbalance issue (typically, there are far more interictal segments than preictal segments) by resampling the data to create a more balanced training set.\n",
        "    *   Features are scaled using `StandardScaler` to normalize their range, which is important for many machine learning models.\n",
        "    *   The dataset is split into training and testing sets for model development and evaluation.\n",
        "\n",
        "7.  **Model Building and Training**:\n",
        "    *   A Long Short-Term Memory (LSTM) model is built using TensorFlow/Keras. LSTMs are well-suited for sequential data like EEG.\n",
        "    *   The model architecture includes LSTM layers, Batch Normalization, and Dropout for improved performance and regularization.\n",
        "    *   The model is compiled with an appropriate optimizer (Adam) and loss function (binary crossentropy) for binary classification.\n",
        "    *   The model is trained on the prepared training data with early stopping and learning rate reduction callbacks to prevent overfitting and optimize the training process.\n",
        "\n",
        "8.  **Model Evaluation**:\n",
        "    *   The trained model is evaluated on the unseen test set.\n",
        "    *   Key metrics like accuracy, precision, recall (sensitivity), specificity, and AUC-ROC are calculated to assess the model's performance in distinguishing between preictal and interictal states.\n",
        "    *   A classification report and confusion matrix provide a detailed view of the model's predictions.\n",
        "    *   The ROC curve is plotted to visualize the trade-off between the true positive rate and false positive rate at various classification thresholds.\n",
        "    *   Training history plots show the model's performance on the training and validation sets over epochs.\n",
        "\n",
        "9.  **Model Saving**:\n",
        "    *   The trained LSTM model and the fitted StandardScaler are saved to files (`lstm_seizure_model.h5` and `scaler.pkl`).\n",
        "    *   These saved artifacts can be used later for making predictions on new, unseen EEG data in a real-time or deployment scenario.\n",
        "\n",
        "This structured approach, from raw data to a trained and evaluated model, provides a clear pipeline for developing a seizure prediction system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EUhfgRt-jj5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
